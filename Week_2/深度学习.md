## deeplizard

>**为什么要用GPU进行计算**

+ 并行计算是一种计算方法，通过并行计算可以将一个特定计算分解成独立的，可以同时进行的更小的计算，将得到的结果重新组合或同步形成原始结果，可被分解的任务数量取决于核数
+ GPU相比CPU有更多的核数,在进行并行计算时可以有更高的效率

>张量（tensor）

+ n维张量即(n维矩阵......)
+ 在张量中，秩、轴、形状分别指代有多少个维度、每个维度的长度与维度与维度长度的信息
+ 运用.dtype方法可得到张量中包含的数据类型，每个数据类型均有gpu版本和cpu版本，张量进行运算需要有相同的数据类型（整型/浮点）（~~不过现在好像会自动转化为浮点~~）
+ 可用`device=torch.device('cuda:0')`来指定该设备为gpu，此时直接输出可以得到一个type为cuda的设备（代表为gpu），index=0说明为第一个gpu，若没有多个gpu但index输入了多个值会导致报错
+ 虽然torch支持多设备，但张量与张量之间的操作必须在同一个设备上发生

>创建张量方法

1. 可以根据已有数据使用numpy来创建一个array，用`.Tensor()`函数来将其转换为张量，用`.tensor()`/`.as_tensor()`/`.from_numpy()`函数来查看其数据类型<br>**后三个为工厂函数，第一个为类构造函数**，鉴于工厂函数有更好的使用说明（？）和更多的配置参数，现更多倾向于使用工厂函数，二者在数据类型上略有出入，类构造函数使用全局缺省值，可用`.get_default_dtype()`查看，而工厂函数则根据输入推断数据类型。当然，也可以人为设置dtype参数（仅工厂函数） <br>值得注意的是，第一与第二种情况运用的是当前数组的情况，而第三与第四种则是映射数组的情况，即会随着数组的变化而变化，该差异是因为在不同方式中分配内存的方式不同，前两个是创建一个额外的输入数据副本，而后二者则是用数字数组在内存中共享数据。**后两个可以让数据在numpy数组与torch张量中无缝高效转换**（因为`.as_tensor()`更加通用所以一般使用这个与
2. 无数据可用时，<br>`.eye(2)`用于返回一个单位张量，即单位矩阵，其中参数用于指定行数`.zeors(2,2)`用于返回一个零张量，其中参数用于指定每个轴的长度，现在这个即表示一个有两个坐标轴的秩为二的张量<br>`.ones(2,2)`用于返回一个全是1.的张量，参数与 `.zeros()`一致<br>`.rand(2,2)`用于生成随机张量，参数也是指定每个轴的长度

>CNN

+ CNN一般由四个数字输出，[样本数量，颜色，长，宽]，最后三个轴已经可以表示一个完整图像，可以在这三个轴中寻找到特定的位置来输出指定图像，第一个轴用于告诉我们由长宽与颜色所组成的特定图像有多少个
+ 例如[3,1,28,28]表示有三个28×28大小，每个都有一个单独的彩色通道所组成的四阶张量，若第一个轴改为1，即代表了仅有一个
+ 张量和基础数据被卷积层转化后，长与宽与颜色通道均有可能因卷积运算所改变，颜色通道的数量根据在层中使用的滤波器的数量而变化。假设有三个滤波器，从卷积层中将得到三个通道输出（从滤波器而来），称作**输出通道**，这三个滤波器中的每一个都可以包含原始的单个输出通道，产生三个输出通道，从而会让**颜色通道数量×3**（每一个原本的颜色都会在滤波器中被过滤出三个通道）。
+ 被滤波器输出的图像不在具有“彩色”，而是由**单一颜色**组成的，称为特征图，特征图是由输入颜色通道和卷积过滤器所产生卷积的结果。把一个输入颜色通道和一个卷积过滤器结合起来，对其再做一个卷积运算得到一个输出通道结果，这个通道称为**特征映射**，其中“特征”是因为其输出代表了图像的特定特征，比如图像边缘

---

>差分隐私

+ 差分隐私通常通过`Opacus`库实现，用于在数据中添加“噪音”，防止攻击者通过观察数据集输入与输出的差异推断出特定个体的信息。可用于保护数据隐私的同时保留数据的统计特性，保证结果的可用性
1. 梯度裁剪：如果样本数据超出某个设定好的最大梯度范数，则将其缩放到阈值范围内
2. 噪声添加：在梯度中添加噪声，常用的噪声有喇布拉斯分布和高斯分布（opacus所用），注意，该参数设置过大可能会降低模型性能
3. 隐私预算计算：每次迭代消耗一定数量的隐私预算，确保整个训练不会超出提前设置好的预算
