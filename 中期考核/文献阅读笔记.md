# Differentially private average consensus: Obstructions, trade-offs, and optimal algorithm design

> 作者：Erfan Nozari  Pavankumar Tallapragada  Jorge Cortés a
> 机构：
> Department of Mechanical and Aerospace Engineering, University of California, San Diego, United States<br>Department of Electrical Engineering, Indian Institute of Science, Bengaluru, India

## 研究问题 Research Question
+ 在多智能体平均共识中，如何实现初始状态的差分隐私保护并保证系统收敛的性能

### 科学问题 Science Question
+ **差分隐私所需求的持续噪声影响**与**多智能体的精确共识需要噪声趋于零**之间的矛盾
+ 所有的DP算法均无法实现零误差收敛

### 研究核心 Core of the research
1. 用理论证明差分隐私与精确平均共识不可同时实现，同时建立隐私保护与性能权衡的数学框架
2. 提出基于拉普拉斯噪声(Laplace Noise)的扰动共识算法
3. 证明基于算法的最优参数配置

### 研究意义 Research significance
+ 对所需共享数据的场景提供了新的隐私保护方案


### 现有方法的不足 Shortcomings of existing algorithm

|方法|缺陷|改进方法|
|--|--|--|
|持续噪音注入|对于收敛性的破坏性较大|改为单次注入持续衰减的噪音|
|依赖拓扑结构|收敛的准确性较差|使用无偏估计设计|
|一次性扰动|仅保护初始状态数据|改为全流程的隐私保护|


### 结论 Conclusion
证明了数据的隐私性与可用性无法同时兼顾，并且就一次性持续衰减的噪音提出了一个优秀的隐私保护方案与最优参数，为医疗、工程等多数据共享的场景提供了一个新的隐私保护方案


---

## 理论与方法 Theory and Method
1. 任何DP算法都无法实现准确的平均共识
2. 提出的算法能以指数速率收敛到无偏估计
3. 最有噪声设计为初始状态注入持续衰减的扰动

#### need to know
+ 隐私预算ε：用于控制隐私保护的强度，通常更小的隐私预算意味着更强的隐私保护
+ 损失函数：用于衡量模型预估值与实际值差异的函数，量化了模型预测的准确性
+ 学习率：控制着模型每次迭代的步长，通常来说学习率过大会导致无法精确找到最优解，学习率过小会导致收敛速度过慢
+ 噪声：人为添加到数据中用于保护隐私的影响因素
+ 噪声缩放因子：用于控制数据中的噪声量，常与敏感度相关
+ 敏感度：算法对于单个数据点变化的敏感程度。表示算法输出与输入中同个数据点变化的最大变化量，通常来说敏感度越高需要更多的噪声来保护数据

+ 算法：
- 差分隐私定义：
$$
\mathbb{p}[x_{ \theta_0^{(1)}} \in \mathcal{0}] \leq e^\epsilon \mathbb{P}[x_{ \theta_0^{(2)}} \in \mathcal{0}]
$$
其中θ为两个数据集中的某个相同元素，P为该事件发生的概率，ε为隐私预算
* 收敛点方差公式：
$$
\text{var}( \theta_ \infty)= \frac{2}{n^2} \sum_{i=1}^n \frac{s_i^2 c_i^2}{1-q_i^2}
$$
其中θ表示参数值，无穷表示θ迭代无穷多次后，var表示方差，s_i表示第i个样本的缩放因子，c_i表示第i个样本的敏感度，q_i表示第i个样本的噪声比例
+ 收敛点表达公式：
$$
\theta_ \infty= \text{Ave}( \theta_{0})+ \frac{1}{n} \sum_{i=1}^n{s_i} \sum_{j=0}^ \infty {\eta_i(j)}
$$
ave表示均值，n表示样本数量，`η_i(j)`表示第i个样本的噪声
+ 状态更新算法：
$$
\theta(k+1)= \theta(k)-hLX(k)+S\eta(k)
$$
h表示学习率，L表示损失函数的梯度，X(k)表示第k次迭代的输入数据，S表示噪声缩放因子，η(k)表示第k次迭代添加的噪声
+ 噪声生成算法（Laplace）：
$$
\eta_i(k) \sim \text{lap}(c_i q_i^k)
$$
k表示迭代次数
+ 参数优化：
$$
s_i=1, \quad q_i= \alpha+(1- \alpha)|s_i-1|
$$
α是一个属于[0,1]中的参数，用于调整噪声比例q_i
+ 收敛时间公式： 
$$
|| \theta_k- \theta_ \infty||<tol
$$
小于号左边表示第k次迭代的参数值与最终收敛值的距离，tol表示容忍度，即认为算法收敛的阈值
+ 局部目标公式
$$
\phi(\alpha, s) = \frac{s^2(\alpha + (1-\alpha)|s-1|)^2}{\alpha^2(1-|s-1|)^2 \left[1 - (\alpha + (1-\alpha)|s-1|)^2\right]}
$$
s 是噪声-状态增益参数，α 是与噪声衰减率 q 相关的参数，且 α= （1−∣s−1∣）/（q−∣s−1∣） ，q 是噪声衰减率，且 q∈(∣s−1∣,1)


---

## 实验 Experiment

|实验|目标|方法|
|--|--|--|
|图3|验证参数s对于收敛的影响|通过调整s的大小观察方差与收敛步数的改变|
|图4|隐私和准确性的权衡|固定s=1的，改变隐私预算ε，观察方差|
|图5|验证收敛点的分布|用10^6次蒙特卡洛模拟|


---

## 总结与思考 Summary and Reflections
对于差分隐私与平均共识算法的首次接触，我对于多智能体与数据的隐私保护有了一个新阶段的认识，无论是对于”噪声“的理解，还是对于”平均共识“的理解，我对这两个论文的绝对关键词进行了一定程度的深挖，同时对其拓展，例如拉普拉斯噪声、收敛速度等常用知识进行了学习。同时第一次进行的文献阅读，给了我新奇的体验，对于英文文献的中英对照查看，对文献的结构的理解，以及对数学推导过程的深思，甚至尝试手推了部分较为简单的公式。同时对于后续实验的阅读与理解，让我又不停的反复理解公式，尝试真正复现实验图，但或许是能力有限，对于图3的复现并没有如此成功，甚至完全没能复现出图4。
